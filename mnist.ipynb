{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yuSahS9iUSf",
        "outputId": "0818365d-3737-460f-b8ae-05e9c44a2efd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 100, Loss: 0.736\n",
            "Epoch 1, Batch 200, Loss: 0.199\n",
            "Epoch 1, Batch 300, Loss: 0.129\n",
            "Epoch 1, Batch 400, Loss: 0.100\n",
            "Epoch 1, Batch 500, Loss: 0.098\n",
            "Epoch 1, Batch 600, Loss: 0.088\n",
            "Epoch 1, Batch 700, Loss: 0.070\n",
            "Epoch 1, Batch 800, Loss: 0.067\n",
            "Epoch 1, Batch 900, Loss: 0.065\n",
            "Epoch 2, Batch 100, Loss: 0.047\n",
            "Epoch 2, Batch 200, Loss: 0.060\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define transforms for the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load the MNIST dataset\n",
        "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Define the CNN architecture for MNIST classification\n",
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNClassifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the CNN classifier\n",
        "classifier = CNNClassifier()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
        "\n",
        "# Training the CNN classifier\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = classifier(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # Print every 100 mini-batches\n",
        "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(classifier.state_dict(), 'mnist_cnn_classifier.pth')\n",
        "print('Model saved.')\n",
        "\n",
        "classifier.load_state_dict(torch.load('mnist_cnn_classifier.pth'))\n",
        "# classifier=torch.load('mnist_cnn_classifier.pth')\n",
        "\n",
        "# Test the trained model on a sample image\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "test_image = datasets.MNIST(root='./data', train=False, download=True, transform=test_transform)\n",
        "test_label = test_image[4][1]\n",
        "test_image = test_image[4][0].unsqueeze(0)\n",
        "\n",
        "classifier.eval()\n",
        "with torch.no_grad():\n",
        "    output = classifier(test_image)\n",
        "predicted_class = torch.argmax(output, dim=1).item()\n",
        "print(f'Predicted class for the sample image: {predicted_class} {test_label}')\n",
        "\n",
        "# Visualize the sample image\n",
        "plt.imshow(test_image.squeeze(), cmap='gray')\n",
        "plt.title(f'Predicted Class: {predicted_class}')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define transforms for the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load the MNIST dataset\n",
        "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Define the CNN architecture for MNIST classification\n",
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNClassifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
        "        self.feature_maps1 = x  # Save feature maps after the first convolution\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the CNN classifier\n",
        "classifier = CNNClassifier()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
        "\n",
        "# Training the CNN classifier\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = classifier(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # Print every 100 mini-batches\n",
        "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(classifier.state_dict(), 'mnist_cnn_classifier.pth')\n",
        "print('Model saved.')\n",
        "\n",
        "# Test the trained model on a sample image\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "test_image = datasets.MNIST(root='./data', train=False, download=True, transform=test_transform)[0][0].unsqueeze(0)\n",
        "classifier.eval()"
      ],
      "metadata": {
        "id": "IEbfJfJvk2mS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the feature maps after the first convolution for the sample image\n",
        "with torch.no_grad():\n",
        "    output = classifier(test_image)\n",
        "feature_maps1 = classifier.feature_maps1\n",
        "\n",
        "# Visualize the feature maps\n",
        "fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n",
        "for i in range(32):\n",
        "    row = i // 8\n",
        "    col = i % 8\n",
        "    axes[row, col].imshow(feature_maps1.squeeze()[i], cmap='gray')\n",
        "    axes[row, col].axis('off')\n",
        "plt.suptitle('Feature Maps after First Convolution')\n",
        "plt.show()\n",
        "\n",
        "# Visualize the sample image\n",
        "plt.imshow(test_image.squeeze(), cmap='gray')\n",
        "plt.title('Sample Image')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JfaYVfrGnOlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the feature maps\n",
        "num_feature_maps = feature_maps1.shape[1]  # Number of output channels\n",
        "fig, axes = plt.subplots(1, num_feature_maps, figsize=(16, 4))\n",
        "for i in range(num_feature_maps):\n",
        "    axes[i].imshow(feature_maps1.squeeze()[i], cmap='gray')\n",
        "    axes[i].axis('off')\n",
        "plt.suptitle('Feature Maps after First Convolution')\n",
        "plt.show()\n",
        "\n",
        "# Visualize the sample image\n",
        "plt.imshow(test_image.squeeze(), cmap='gray')\n",
        "plt.title('Sample Image')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gJC9x_OWnh2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the final filters from the convolutional layers\n",
        "final_filters_conv1 = classifier.conv1.weight.data\n",
        "final_filters_conv2 = classifier.conv2.weight.data\n",
        "\n",
        "# Visualize the final filters\n",
        "fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n",
        "for i in range(32):\n",
        "    row = i // 8\n",
        "    col = i % 8\n",
        "    axes[row, col].imshow(final_filters_conv1[i].squeeze(), cmap='gray')\n",
        "    axes[row, col].axis('off')\n",
        "plt.suptitle('Final Filters from Conv1 (32 Filters)')\n",
        "plt.show()\n",
        "\n",
        "# fig, axes = plt.subplots(8, 8, figsize=(16, 16))\n",
        "# for i in range(64):\n",
        "#     row = i // 8\n",
        "#     col = i % 8\n",
        "#     axes[row, col].imshow(final_filters_conv2[i].squeeze(), cmap='gray')\n",
        "#     axes[row, col].axis('off')\n",
        "# plt.suptitle('Final Filters from Conv2 (64 Filters)')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "m-VTa-vDqWZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the filter values to [0, 1]\n",
        "final_filters_conv1 = (final_filters_conv1 - final_filters_conv1.min()) / (final_filters_conv1.max() - final_filters_conv1.min())\n",
        "final_filters_conv2 = (final_filters_conv2 - final_filters_conv2.min()) / (final_filters_conv2.max() - final_filters_conv2.min())\n",
        "\n",
        "# Visualize the final filters\n",
        "fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n",
        "for i in range(32):\n",
        "    row = i // 8\n",
        "    col = i % 8\n",
        "    axes[row, col].imshow(final_filters_conv1[i].squeeze(), cmap='gray')\n",
        "    axes[row, col].axis('off')\n",
        "plt.suptitle('Final Filters from Conv1 (32 Filters)')\n",
        "plt.show()\n",
        "\n",
        "fig, axes = plt.subplots(8, 8, figsize=(16, 16))\n",
        "for i in range(64):\n",
        "    row = i // 8\n",
        "    col = i % 8\n",
        "    axes[row, col].imshow(final_filters_conv2[i].squeeze(), cmap='gray')\n",
        "    axes[row, col].axis('off')\n",
        "plt.suptitle('Final Filters from Conv2 (64 Filters)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b1heTD2Z2p3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NCRZvdeo30k9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}